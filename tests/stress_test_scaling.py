"""
å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•ä¸æ‰©å±•æ€§åˆ†æ

æµ‹è¯•ç›®æ ‡ï¼š
1. æ¨¡æ‹Ÿ 20 ä¸ªä¸åŒå¸ç§çš„ Tick å’Œ Book æ•°æ®ï¼ˆä¸‡æ¬¡/ç§’é¢‘ç‡ï¼‰
2. è§‚å¯Ÿ MarketDataManager çš„ latency_stats å’Œ EventBus çš„æ’é˜Ÿå»¶è¿Ÿ
3. å†…å­˜å®¡è®¡ï¼š1 ä¸ªå¸ç§ vs 20 ä¸ªå¸ç§å¹¶å‘ä¸‹çš„å†…å­˜å¢é•¿æ›²çº¿
4. æ£€æŸ¥ PositionSizer çš„ deque å’Œ MarketDataManager çš„å¿«ç…§ç¼“å­˜æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼
5. æ€§èƒ½ç“¶é¢ˆå®šä½ï¼šæ—¥å¿— IO è¿‡å¤š vs asyncio.Lock ç«äº‰
6. ä¼˜åŒ–æ–¹æ¡ˆï¼šå¼‚æ­¥æ—¥å¿—ã€è½»é‡çº§ EventBus åˆ†å‘

ä½¿ç”¨æ–¹æ³•ï¼š
    python tests/stress_test_scaling.py
"""

import asyncio
import time
import random
import tracemalloc
import psutil
import os
from typing import Dict, List, Tuple
from collections import defaultdict
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.core.event_bus import EventBus, Event, EventType, EventPriority
from src.market.market_data_manager import MarketDataManager
from src.strategies.hft.components.position_sizer import PositionSizer, PositionSizingConfig

# æ—¥å¿—é…ç½®
import logging
logging.basicConfig(
    level=logging.INFO,  # ğŸ”¥ [æµ‹è¯•] INFO çº§åˆ«ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ========== æµ‹è¯•é…ç½® ==========

# æµ‹è¯•å¸ç§åˆ—è¡¨ï¼ˆ20 ä¸ªï¼‰
TEST_SYMBOLS = [
    'BTC-USDT-SWAP', 'ETH-USDT-SWAP', 'SOL-USDT-SWAP', 'DOGE-USDT-SWAP',
    'XRP-USDT-SWAP', 'ADA-USDT-SWAP', 'AVAX-USDT-SWAP', 'DOT-USDT-SWAP',
    'MATIC-USDT-SWAP', 'LINK-USDT-SWAP', 'UNI-USDT-SWAP', 'LTC-USDT-SWAP',
    'BCH-USDT-SWAP', 'XLM-USDT-SWAP', 'ALGO-USDT-SWAP', 'VET-USDT-SWAP',
    'FIL-USDT-SWAP', 'ICP-USDT-SWAP', 'TRX-USDT-SWAP', 'NEAR-USDT-SWAP'
]

# æµ‹è¯•å‚æ•°
TEST_DURATION_SECONDS = 30  # æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
TICKS_PER_SECOND_PER_SYMBOL = 500  # æ¯ä¸ªå¸ç§æ¯ç§’ Tick æ•°ï¼ˆ500 * 20 = 10000 TPSï¼‰
BOOK_UPDATES_PER_SECOND = 100  # æ¯ä¸ªå¸ç§æ¯ç§’ Book æ›´æ–°æ•°

# æ€§èƒ½é˜ˆå€¼
WARNING_LATENCY_MS = 10.0  # è­¦å‘Šé˜ˆå€¼
CRITICAL_LATENCY_MS = 50.0  # ä¸¥é‡é˜ˆå€¼


# ========== æ€§èƒ½ç›‘æ§å·¥å…· ==========

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.start_time = time.time()
        self.memory_snapshots: List[Tuple[float, float]] = []  # (timestamp, memory_mb)
        self.event_bus_stats: List[Dict] = []
        self.market_data_stats: List[Dict] = []
        self.lock_stats: Dict[str, int] = defaultdict(int)  # è®°å½•é”ç«äº‰æ¬¡æ•°

    def record_memory(self):
        """è®°å½•å†…å­˜å¿«ç…§"""
        process = psutil.Process(os.getpid())
        memory_mb = process.memory_info().rss / 1024 / 1024  # MB
        elapsed = time.time() - self.start_time
        self.memory_snapshots.append((elapsed, memory_mb))
        return memory_mb

    def record_event_bus_stats(self, event_bus: EventBus):
        """è®°å½• EventBus ç»Ÿè®¡"""
        stats = event_bus.get_stats()
        stats['timestamp'] = time.time() - self.start_time
        self.event_bus_stats.append(stats)

    def record_market_data_stats(self, market_data_manager: MarketDataManager):
        """è®°å½• MarketDataManager ç»Ÿè®¡"""
        stats = market_data_manager.get_latency_stats()
        stats['timestamp'] = time.time() - self.start_time
        self.market_data_stats.append(stats)

    def record_lock_contention(self, component: str):
        """è®°å½•é”ç«äº‰"""
        self.lock_stats[component] += 1

    def get_memory_growth_rate(self) -> float:
        """è®¡ç®—å†…å­˜å¢é•¿ç‡ï¼ˆMB/ç§’ï¼‰"""
        if len(self.memory_snapshots) < 2:
            return 0.0

        first_time, first_mem = self.memory_snapshots[0]
        last_time, last_mem = self.memory_snapshots[-1]
        time_diff = last_time - first_time

        if time_diff == 0:
            return 0.0

        return (last_mem - first_mem) / time_diff

    def get_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        # å†…å­˜ç»Ÿè®¡
        if self.memory_snapshots:
            memories = [mem for _, mem in self.memory_snapshots]
            memory_summary = {
                'initial_mb': memories[0],
                'final_mb': memories[-1],
                'peak_mb': max(memories),
                'growth_mb': memories[-1] - memories[0],
                'growth_rate_mb_per_sec': self.get_memory_growth_rate()
            }
        else:
            memory_summary = {}

        # EventBus ç»Ÿè®¡
        if self.event_bus_stats:
            queue_sizes = [s['queue_size'] for s in self.event_bus_stats]
            event_bus_summary = {
                'max_queue_size': max(queue_sizes),
                'avg_queue_size': sum(queue_sizes) / len(queue_sizes),
                'total_published': self.event_bus_stats[-1]['published'],
                'total_processed': self.event_bus_stats[-1]['processed'],
                'total_errors': self.event_bus_stats[-1]['errors']
            }
        else:
            event_bus_summary = {}

        # MarketDataManager ç»Ÿè®¡
        if self.market_data_stats:
            counts = [s['count'] for s in self.market_data_stats]
            avg_latencies = [s['avg_us'] / 1000.0 for s in self.market_data_stats if s['count'] > 0]  # è½¬æ¢ä¸º ms
            max_latencies = [s['max_us'] / 1000.0 for s in self.market_data_stats if s['count'] > 0]
            market_data_summary = {
                'total_updates': self.market_data_stats[-1]['count'],
                'avg_latency_ms': sum(avg_latencies) / len(avg_latencies) if avg_latencies else 0.0,
                'max_latency_ms': max(max_latencies) if max_latencies else 0.0,
                'max_latency_ms_critical': max(max_latencies) if max_latencies else 0.0 > CRITICAL_LATENCY_MS
            }
        else:
            market_data_summary = {}

        # é”ç«äº‰ç»Ÿè®¡
        lock_summary = dict(self.lock_stats)

        return {
            'duration_seconds': time.time() - self.start_time,
            'memory': memory_summary,
            'event_bus': event_bus_summary,
            'market_data': market_data_summary,
            'lock_contention': lock_summary
        }


# ========== æ•°æ®ç”Ÿæˆå™¨ ==========

class DataGenerator:
    """æ•°æ®ç”Ÿæˆå™¨ï¼ˆæ¨¡æ‹ŸçœŸå®å¸‚åœºæ•°æ®ï¼‰"""

    def __init__(self, symbol: str, base_price: float):
        self.symbol = symbol
        self.base_price = base_price
        self.current_price = base_price
        self.tick_size = base_price * 0.0001  # 0.01%

    def generate_tick_event(self) -> Event:
        """ç”Ÿæˆ Tick äº‹ä»¶"""
        # éšæœºä»·æ ¼æ³¢åŠ¨ï¼ˆÂ±0.01%ï¼‰
        price_change = self.current_price * random.uniform(-0.0001, 0.0001)
        self.current_price += price_change

        # éšæœºäº¤æ˜“é‡
        size = random.uniform(0.1, 10.0)

        return Event(
            type=EventType.TICK,
            data={
                'symbol': self.symbol,
                'price': self.current_price,
                'size': size,
                'side': random.choice(['buy', 'sell']),
                'timestamp': int(time.time() * 1000)
            },
            source="stress_test"
        )

    def generate_book_event(self) -> Event:
        """ç”Ÿæˆ Book äº‹ä»¶"""
        # éšæœºä»·æ ¼æ³¢åŠ¨ï¼ˆÂ±0.02%ï¼‰
        price_change = self.current_price * random.uniform(-0.0002, 0.0002)
        self.current_price += price_change

        # ç”Ÿæˆä¹°ç›˜
        bids = []
        for i in range(5):
            bid_price = self.current_price * (1.0 - 0.0001 * (i + 1))
            bid_size = random.uniform(10.0, 100.0)
            bids.append([bid_price, bid_size])

        # ç”Ÿæˆå–ç›˜
        asks = []
        for i in range(5):
            ask_price = self.current_price * (1.0 + 0.0001 * (i + 1))
            ask_size = random.uniform(10.0, 100.0)
            asks.append([ask_price, ask_size])

        return Event(
            type=EventType.BOOK_EVENT,
            data={
                'symbol': self.symbol,
                'bids': bids,
                'asks': asks,
                'timestamp': int(time.time() * 1000)
            },
            source="stress_test"
        )


# ========== å‹åŠ›æµ‹è¯• ==========

async def stress_test_single_symbol():
    """å•å¸ç§å‹åŠ›æµ‹è¯•ï¼ˆåŸºå‡†æµ‹è¯•ï¼‰"""
    logger.info("=" * 80)
    logger.info("ğŸ§ª [æµ‹è¯•1] å•å¸ç§å‹åŠ›æµ‹è¯•ï¼ˆåŸºå‡†ï¼‰")
    logger.info("=" * 80)

    # åˆå§‹åŒ–
    event_bus = EventBus()
    market_data_manager = MarketDataManager(event_bus)
    monitor = PerformanceMonitor()

    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generator = DataGenerator('BTC-USDT-SWAP', 50000.0)

    # å¯åŠ¨ EventBus
    await event_bus.start()

    # åˆå§‹å†…å­˜
    monitor.record_memory()

    # æµ‹è¯•å¾ªç¯
    start_time = time.time()
    tick_interval = 1.0 / TICKS_PER_SECOND_PER_SYMBOL
    book_interval = 1.0 / BOOK_UPDATES_PER_SECOND
    last_tick_time = 0
    last_book_time = 0

    logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•: æ—¶é•¿={TEST_DURATION_SECONDS}s, TPS={TICKS_PER_SECOND_PER_SYMBOL}, BPS={BOOK_UPDATES_PER_SECOND}")

    try:
        while time.time() - start_time < TEST_DURATION_SECONDS:
            current_time = time.time()

            # ç”Ÿæˆ Tick äº‹ä»¶
            if current_time - last_tick_time >= tick_interval:
                tick_event = generator.generate_tick_event()
                await event_bus.put(tick_event, priority=EventPriority.TICK)
                last_tick_time = current_time

            # ç”Ÿæˆ Book äº‹ä»¶
            if current_time - last_book_time >= book_interval:
                book_event = generator.generate_book_event()
                await event_bus.put(book_event, priority=EventPriority.TICK)
                last_book_time = current_time

            # è®°å½•ç»Ÿè®¡ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
            if int(current_time) > int(start_time):
                monitor.record_memory()
                monitor.record_event_bus_stats(event_bus)
                monitor.record_market_data_stats(market_data_manager)

            # çŸ­æš‚ä¼‘çœ é¿å… CPU å ç”¨è¿‡é«˜
            await asyncio.sleep(0.001)

    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        await event_bus.stop()

    # æœ€ç»ˆå†…å­˜
    monitor.record_memory()

    # ç”ŸæˆæŠ¥å‘Š
    summary = monitor.get_summary()
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š [æµ‹è¯•1] å•å¸ç§å‹åŠ›æµ‹è¯•ç»“æœ")
    logger.info("=" * 80)
    logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {summary['duration_seconds']:.1f}s")
    logger.info(f"ğŸ’¾ å†…å­˜: åˆå§‹={summary['memory']['initial_mb']:.2f}MB, "
                f"æœ€ç»ˆ={summary['memory']['final_mb']:.2f}MB, "
                f"å³°å€¼={summary['memory']['peak_mb']:.2f}MB, "
                f"å¢é•¿={summary['memory']['growth_mb']:.2f}MB "
                f"({summary['memory']['growth_rate_mb_per_sec']:.3f}MB/s)")
    logger.info(f"ğŸ“¡ EventBus: å‘å¸ƒ={summary['event_bus']['total_published']}, "
                f"å¤„ç†={summary['event_bus']['total_processed']}, "
                f"é”™è¯¯={summary['event_bus']['total_errors']}, "
                f"æœ€å¤§é˜Ÿåˆ—={summary['event_bus']['max_queue_size']}")
    logger.info(f"ğŸ“Š MarketData: æ›´æ–°={summary['market_data']['total_updates']}, "
                f"å¹³å‡å»¶è¿Ÿ={summary['market_data']['avg_latency_ms']:.3f}ms, "
                f"æœ€å¤§å»¶è¿Ÿ={summary['market_data']['max_latency_ms']:.3f}ms")

    # ğŸ”¥ [ç“¶é¢ˆå®šä½] æ£€æŸ¥å»¶è¿Ÿæ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if summary['market_data']['avg_latency_ms'] > WARNING_LATENCY_MS:
        logger.warning(f"âš ï¸ [ç“¶é¢ˆè­¦å‘Š] MarketDataManager å¹³å‡å»¶è¿Ÿ {summary['market_data']['avg_latency_ms']:.3f}ms > {WARNING_LATENCY_MS}ms")
        if summary['market_data']['avg_latency_ms'] > CRITICAL_LATENCY_MS:
            logger.error(f"ğŸš¨ [ç“¶é¢ˆä¸¥é‡] MarketDataManager å¹³å‡å»¶è¿Ÿ {summary['market_data']['avg_latency_ms']:.3f}ms > {CRITICAL_LATENCY_MS}ms")

    return summary


async def stress_test_multi_symbols(num_symbols: int = 20):
    """å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•"""
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ§ª [æµ‹è¯•2] å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•ï¼ˆ{num_symbols} ä¸ªå¸ç§ï¼‰")
    logger.info("=" * 80)

    # åˆå§‹åŒ–
    event_bus = EventBus()
    market_data_manager = MarketDataManager(event_bus)
    monitor = PerformanceMonitor()

    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generators = []
    for symbol in TEST_SYMBOLS[:num_symbols]:
        base_price = random.uniform(1.0, 50000.0)  # éšæœºä»·æ ¼
        generator = DataGenerator(symbol, base_price)
        generators.append(generator)

    # å¯åŠ¨ EventBus
    await event_bus.start()

    # åˆå§‹å†…å­˜
    monitor.record_memory()

    # æµ‹è¯•å¾ªç¯
    start_time = time.time()
    tick_interval = 1.0 / TICKS_PER_SECOND_PER_SYMBOL
    book_interval = 1.0 / BOOK_UPDATES_PER_SECOND
    last_tick_time = 0
    last_book_time = 0

    total_tps = TICKS_PER_SECOND_PER_SYMBOL * num_symbols
    total_bps = BOOK_UPDATES_PER_SECOND * num_symbols

    logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•: æ—¶é•¿={TEST_DURATION_SECONDS}s, "
                f"å¸ç§æ•°={num_symbols}, æ€»TPS={total_tps}, æ€»BPS={total_bps}")

    try:
        while time.time() - start_time < TEST_DURATION_SECONDS:
            current_time = time.time()

            # ç”Ÿæˆæ‰€æœ‰å¸ç§çš„ Tick äº‹ä»¶
            if current_time - last_tick_time >= tick_interval:
                for generator in generators:
                    tick_event = generator.generate_tick_event()
                    await event_bus.put(tick_event, priority=EventPriority.TICK)
                last_tick_time = current_time

            # ç”Ÿæˆæ‰€æœ‰å¸ç§çš„ Book äº‹ä»¶
            if current_time - last_book_time >= book_interval:
                for generator in generators:
                    book_event = generator.generate_book_event()
                    await event_bus.put(book_event, priority=EventPriority.TICK)
                last_book_time = current_time

            # è®°å½•ç»Ÿè®¡ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
            if int(current_time) > int(start_time):
                monitor.record_memory()
                monitor.record_event_bus_stats(event_bus)
                monitor.record_market_data_stats(market_data_manager)

            # çŸ­æš‚ä¼‘çœ é¿å… CPU å ç”¨è¿‡é«˜
            await asyncio.sleep(0.001)

    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        await event_bus.stop()

    # æœ€ç»ˆå†…å­˜
    monitor.record_memory()

    # ç”ŸæˆæŠ¥å‘Š
    summary = monitor.get_summary()
    logger.info("\n" + "=" * 80)
    logger.info(f"ğŸ“Š [æµ‹è¯•2] å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•ç»“æœï¼ˆ{num_symbols} ä¸ªå¸ç§ï¼‰")
    logger.info("=" * 80)
    logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {summary['duration_seconds']:.1f}s")
    logger.info(f"ğŸ’¾ å†…å­˜: åˆå§‹={summary['memory']['initial_mb']:.2f}MB, "
                f"æœ€ç»ˆ={summary['memory']['final_mb']:.2f}MB, "
                f"å³°å€¼={summary['memory']['peak_mb']:.2f}MB, "
                f"å¢é•¿={summary['memory']['growth_mb']:.2f}MB "
                f"({summary['memory']['growth_rate_mb_per_sec']:.3f}MB/s)")
    logger.info(f"ğŸ“¡ EventBus: å‘å¸ƒ={summary['event_bus']['total_published']}, "
                f"å¤„ç†={summary['event_bus']['total_processed']}, "
                f"é”™è¯¯={summary['event_bus']['total_errors']}, "
                f"æœ€å¤§é˜Ÿåˆ—={summary['event_bus']['max_queue_size']}")
    logger.info(f"ğŸ“Š MarketData: æ›´æ–°={summary['market_data']['total_updates']}, "
                f"å¹³å‡å»¶è¿Ÿ={summary['market_data']['avg_latency_ms']:.3f}ms, "
                f"æœ€å¤§å»¶è¿Ÿ={summary['market_data']['max_latency_ms']:.3f}ms")

    # ğŸ”¥ [ç“¶é¢ˆå®šä½] æ£€æŸ¥å»¶è¿Ÿæ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if summary['market_data']['avg_latency_ms'] > WARNING_LATENCY_MS:
        logger.warning(f"âš ï¸ [ç“¶é¢ˆè­¦å‘Š] MarketDataManager å¹³å‡å»¶è¿Ÿ {summary['market_data']['avg_latency_ms']:.3f}ms > {WARNING_LATENCY_MS}ms")
        if summary['market_data']['avg_latency_ms'] > CRITICAL_LATENCY_MS:
            logger.error(f"ğŸš¨ [ç“¶é¢ˆä¸¥é‡] MarketDataManager å¹³å‡å»¶è¿Ÿ {summary['market_data']['avg_latency_ms']:.3f}ms > {CRITICAL_LATENCY_MS}ms")

    return summary


async def test_memory_leak():
    """å†…å­˜æ³„æ¼æµ‹è¯•"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ§ª [æµ‹è¯•3] å†…å­˜æ³„æ¼æµ‹è¯•")
    logger.info("=" * 80)

    # å¯åŠ¨å†…å­˜è·Ÿè¸ª
    tracemalloc.start()

    # åˆå§‹åŒ–
    event_bus = EventBus()
    market_data_manager = MarketDataManager(event_bus)
    monitor = PerformanceMonitor()

    # åˆ›å»º PositionSizerï¼ˆæ£€æŸ¥ deque æ˜¯å¦æœ‰å†…å­˜æ³„æ¼ï¼‰
    config = PositionSizingConfig()
    position_sizer = PositionSizer(config, ct_val=1.0)

    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generator = DataGenerator('BTC-USDT-SWAP', 50000.0)

    # å¯åŠ¨ EventBus
    await event_bus.start()

    # åˆå§‹å†…å­˜å¿«ç…§
    snapshot1 = tracemalloc.take_snapshot()

    # æµ‹è¯•å¾ªç¯ï¼ˆæŒç»­ 60 ç§’ï¼‰
    start_time = time.time()
    test_duration = 60  # ç§’

    logger.info(f"ğŸš€ å¼€å§‹å†…å­˜æ³„æ¼æµ‹è¯•: æ—¶é•¿={test_duration}s")

    try:
        while time.time() - start_time < test_duration:
            # ç”Ÿæˆå¤§é‡äº‹ä»¶
            for _ in range(100):
                tick_event = generator.generate_tick_event()
                await event_bus.put(tick_event, priority=EventPriority.TICK)

                # æ›´æ–° PositionSizerï¼ˆæ£€æŸ¥ dequeï¼‰
                current_price = tick_event.data['price']
                order_book = {
                    'bids': [[current_price * 0.999, 100.0]],
                    'asks': [[current_price * 1.001, 100.0]]
                }
                position_sizer.calculate_order_size(
                    account_equity=10000.0,
                    order_book=order_book,
                    signal_ratio=5.0,
                    current_price=current_price,
                    side='buy'
                )

            await asyncio.sleep(0.01)

    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        await event_bus.stop()

    # æœ€ç»ˆå†…å­˜å¿«ç…§
    snapshot2 = tracemalloc.take_snapshot()

    # å¯¹æ¯”å¿«ç…§
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š [æµ‹è¯•3] å†…å­˜æ³„æ¼åˆ†æ")
    logger.info("=" * 80)

    # æ‰“å°å‰ 20 ä¸ªå†…å­˜å¢é•¿ç‚¹
    logger.info("ğŸ” å†…å­˜å¢é•¿ Top 20:")
    for stat in top_stats[:20]:
        logger.info(f"  {stat}")

    # åˆ†æ PositionSizer çš„ deque
    state = position_sizer.get_state()
    logger.info(f"\nğŸ“Š PositionSizer çŠ¶æ€:")
    logger.info(f"  ä»·æ ¼å†å²é•¿åº¦: {state['price_history_len']}")
    logger.info(f"  é…ç½® maxlen: {state['config']['volatility_ema_period']}")
    if state['price_history_len'] > state['config']['volatility_ema_period']:
        logger.warning(f"âš ï¸ [å†…å­˜æ³„æ¼è­¦å‘Š] PositionSizer ä»·æ ¼å†å²è¶…å‡º maxlen!")
    else:
        logger.info(f"âœ… PositionSizer deque æ­£å¸¸ï¼ˆæœªè¶…å‡º maxlenï¼‰")

    # åˆ†æ MarketDataManager çš„å¿«ç…§ç¼“å­˜
    logger.info(f"\nğŸ“Š MarketDataManager çŠ¶æ€:")
    logger.info(f"  è®¢å•ç°¿ç¼“å­˜: 1 ä¸ªå¸ç§")
    logger.info(f"  è¡Œæƒ…ç¼“å­˜: 1 ä¸ªå¸ç§")
    logger.info(f"âœ… MarketDataManager ä½¿ç”¨å­—å…¸ç¼“å­˜ï¼Œè‡ªåŠ¨ç®¡ç†å†…å­˜")

    tracemalloc.stop()


async def test_lock_contention():
    """é”ç«äº‰æµ‹è¯•"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ§ª [æµ‹è¯•4] é”ç«äº‰æµ‹è¯•")
    logger.info("=" * 80)

    # åˆå§‹åŒ–
    event_bus = EventBus()
    market_data_manager = MarketDataManager(event_bus)
    monitor = PerformanceMonitor()

    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generators = []
    for symbol in TEST_SYMBOLS[:5]:  # 5 ä¸ªå¸ç§
        base_price = random.uniform(1.0, 50000.0)
        generator = DataGenerator(symbol, base_price)
        generators.append(generator)

    # å¯åŠ¨ EventBus
    await event_bus.start()

    # æµ‹è¯•å¾ªç¯
    start_time = time.time()
    test_duration = 30  # ç§’

    logger.info(f"ğŸš€ å¼€å§‹é”ç«äº‰æµ‹è¯•: æ—¶é•¿={test_duration}s, å¸ç§æ•°=5")

    try:
        while time.time() - start_time < test_duration:
            # å¹¶å‘ç”Ÿæˆäº‹ä»¶ï¼ˆæ¨¡æ‹Ÿé«˜å¹¶å‘ï¼‰
            tasks = []
            for generator in generators:
                # ç”Ÿæˆ Tick
                tick_event = generator.generate_tick_event()
                tasks.append(event_bus.put(tick_event, priority=EventPriority.TICK))

                # ç”Ÿæˆ Book
                book_event = generator.generate_book_event()
                tasks.append(event_bus.put(book_event, priority=EventPriority.TICK))

                # è¯»å–å¿«ç…§ï¼ˆè§¦å‘é”ç«äº‰ï¼‰
                tasks.append(market_data_manager.get_order_book_snapshot(generator.symbol))

            await asyncio.gather(*tasks)

            await asyncio.sleep(0.01)

    except KeyboardInterrupt:
        logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        await event_bus.stop()

    # ç”ŸæˆæŠ¥å‘Š
    summary = monitor.get_summary()
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š [æµ‹è¯•4] é”ç«äº‰æµ‹è¯•ç»“æœ")
    logger.info("=" * 80)
    logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {summary['duration_seconds']:.1f}s")
    logger.info(f"ğŸ’¾ å†…å­˜: å¢é•¿={summary['memory']['growth_mb']:.2f}MB "
                f"({summary['memory']['growth_rate_mb_per_sec']:.3f}MB/s)")
    logger.info(f"ğŸ“Š MarketData: å¹³å‡å»¶è¿Ÿ={summary['market_data']['avg_latency_ms']:.3f}ms")

    # ğŸ”¥ [ç“¶é¢ˆå®šä½] åˆ†æé”ç«äº‰
    if summary['market_data']['avg_latency_ms'] > WARNING_LATENCY_MS:
        logger.warning(f"âš ï¸ [ç“¶é¢ˆè­¦å‘Š] MarketDataManager å»¶è¿Ÿè¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨é”ç«äº‰")
        logger.info(f"ğŸ’¡ å»ºè®®:")
        logger.info(f"  1. å‡å°‘é”çš„ç²’åº¦ï¼ˆä¾‹å¦‚ï¼Œæ¯ä¸ª symbol ä½¿ç”¨ç‹¬ç«‹çš„ Lockï¼‰")
        logger.info(f"  2. ä½¿ç”¨è¯»å†™é”ï¼ˆasyncio.Lock æ›¿æ¢ä¸º asyncio.RWLockï¼‰")
        logger.info(f"  3. å‡å°‘å¿«ç…§é¢‘ç‡")
    else:
        logger.info(f"âœ… é”ç«äº‰æ­£å¸¸")


# ========== ä¸»ç¨‹åº ==========

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸš€ Athena Trader å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•")
    logger.info("=" * 80)

    results = {}

    # æµ‹è¯•1: å•å¸ç§å‹åŠ›æµ‹è¯•
    try:
        results['single_symbol'] = await stress_test_single_symbol()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•1å¤±è´¥: {e}", exc_info=True)

    # ç­‰å¾… 5 ç§’
    logger.info("\nâ±ï¸ ç­‰å¾… 5 ç§’...")
    await asyncio.sleep(5)

    # æµ‹è¯•2: å¤šå¸ç§å¹¶å‘å‹åŠ›æµ‹è¯•
    try:
        results['multi_symbol_20'] = await stress_test_multi_symbols(20)
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•2å¤±è´¥: {e}", exc_info=True)

    # ç­‰å¾… 5 ç§’
    logger.info("\nâ±ï¸ ç­‰å¾… 5 ç§’...")
    await asyncio.sleep(5)

    # æµ‹è¯•3: å†…å­˜æ³„æ¼æµ‹è¯•
    try:
        await test_memory_leak()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•3å¤±è´¥: {e}", exc_info=True)

    # ç­‰å¾… 5 ç§’
    logger.info("\nâ±ï¸ ç­‰å¾… 5 ç§’...")
    await asyncio.sleep(5)

    # æµ‹è¯•4: é”ç«äº‰æµ‹è¯•
    try:
        await test_lock_contention()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•4å¤±è´¥: {e}", exc_info=True)

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
    logger.info("=" * 80)

    # å¯¹æ¯”å•å¸ç§ vs å¤šå¸ç§
    if 'single_symbol' in results and 'multi_symbol_20' in results:
        single = results['single_symbol']
        multi = results['multi_symbol_20']

        logger.info(f"\nğŸ“ˆ æ‰©å±•æ€§åˆ†æï¼ˆå•å¸ç§ vs 20 å¸ç§ï¼‰:")
        logger.info(f"  å†…å­˜å¢é•¿:")
        logger.info(f"    å•å¸ç§: {single['memory']['growth_mb']:.2f}MB "
                    f"({single['memory']['growth_rate_mb_per_sec']:.3f}MB/s)")
        logger.info(f"    20å¸ç§: {multi['memory']['growth_mb']:.2f}MB "
                    f"({multi['memory']['growth_rate_mb_per_sec']:.3f}MB/s)")
        logger.info(f"    æ‰©å±•æ¯”ä¾‹: {multi['memory']['growth_rate_mb_per_sec'] / single['memory']['growth_rate_mb_per_sec']:.2f}x")

        logger.info(f"\n  å»¶è¿Ÿåˆ†æ:")
        logger.info(f"    å•å¸ç§: å¹³å‡={single['market_data']['avg_latency_ms']:.3f}ms")
        logger.info(f"    20å¸ç§: å¹³å‡={multi['market_data']['avg_latency_ms']:.3f}ms")
        logger.info(f"    å»¶è¿Ÿå¢é•¿: {(multi['market_data']['avg_latency_ms'] / single['market_data']['avg_latency_ms'] - 1) * 100:.1f}%")

        logger.info(f"\n  EventBus æ€§èƒ½:")
        logger.info(f"    å•å¸ç§: å‘å¸ƒ={single['event_bus']['total_published']}, "
                    f"æœ€å¤§é˜Ÿåˆ—={single['event_bus']['max_queue_size']}")
        logger.info(f"    20å¸ç§: å‘å¸ƒ={multi['event_bus']['total_published']}, "
                    f"æœ€å¤§é˜Ÿåˆ—={multi['event_bus']['max_queue_size']}")

    # ä¼˜åŒ–å»ºè®®
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
    logger.info("=" * 80)

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
    if 'multi_symbol_20' in results:
        multi = results['multi_symbol_20']

        # 1. å»¶è¿Ÿä¼˜åŒ–
        if multi['market_data']['avg_latency_ms'] > WARNING_LATENCY_MS:
            logger.warning(f"âš ï¸ å»¶è¿Ÿè¿‡é«˜ ({multi['market_data']['avg_latency_ms']:.3f}ms)ï¼Œå»ºè®®:")
            logger.info(f"  1. ä½¿ç”¨å¼‚æ­¥æ—¥å¿—ï¼ˆaiologger æˆ–ç±»ä¼¼åº“ï¼‰")
            logger.info(f"  2. å‡å°‘æ—¥å¿—è¾“å‡ºé¢‘ç‡ï¼ˆDEBUG çº§åˆ«æ”¹ä¸º INFOï¼‰")
            logger.info(f"  3. ä½¿ç”¨æ›´è½»é‡çš„ EventBus åˆ†å‘æœºåˆ¶ï¼ˆä¾‹å¦‚ï¼Œå¹¿æ’­æ¨¡å¼ï¼‰")
            logger.info(f"  4. è€ƒè™‘ä½¿ç”¨ uvloop æ›¿æ¢æ ‡å‡† asyncio å¾ªç¯")

        # 2. å†…å­˜ä¼˜åŒ–
        if multi['memory']['growth_rate_mb_per_sec'] > 1.0:  # è¶…è¿‡ 1MB/s
            logger.warning(f"âš ï¸ å†…å­˜å¢é•¿è¿‡å¿« ({multi['memory']['growth_rate_mb_per_sec']:.3f}MB/s)ï¼Œå»ºè®®:")
            logger.info(f"  1. é™åˆ¶ MarketDataManager å¿«ç…§ç¼“å­˜çš„å¤§å°ï¼ˆä¾‹å¦‚ï¼ŒLRU ç¼“å­˜ï¼‰")
            logger.info(f"  2. å®šæœŸæ¸…ç† EventBus çš„å»¶è¿Ÿç»Ÿè®¡ï¼ˆåªä¿ç•™æœ€è¿‘ N ä¸ªæ ·æœ¬ï¼‰")
            logger.info(f"  3. æ£€æŸ¥ PositionSizer çš„ deque æ˜¯å¦æœ‰å†…å­˜æ³„æ¼")

        # 3. é”ç«äº‰ä¼˜åŒ–
        if multi['market_data']['avg_latency_ms'] > WARNING_LATENCY_MS:
            logger.warning(f"âš ï¸ å¯èƒ½å­˜åœ¨é”ç«äº‰ï¼Œå»ºè®®:")
            logger.info(f"  1. æ¯ä¸ª symbol ä½¿ç”¨ç‹¬ç«‹çš„ Lockï¼ˆå‡å°‘é”ç²’åº¦ï¼‰")
            logger.info(f"  2. ä½¿ç”¨è¯»å†™é”ï¼ˆasyncio.RWLockï¼‰æ›¿ä»£ asyncio.Lock")
            logger.info(f"  3. å‡å°‘å¿«ç…§é¢‘ç‡ï¼ˆä¾‹å¦‚ï¼Œæ¯ 10ms åªæ›´æ–°ä¸€æ¬¡ï¼‰")

        else:
            logger.info(f"âœ… æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")

    # ä¿å­˜æµ‹è¯•ç»“æœ
    results_file = 'tests/stress_test_results.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logger.info(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    logger.info("=" * 80)


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
